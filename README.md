# ğŸ§  NEURO-NANO

**Neuro-Nano** is a lightweight local AI inference setup using a quantized GGUF model, designed for fast execution, offline usage, and low-resource systems.

This repository contains the **inference code and runtime tools**.
The **model weights are hosted separately** on Hugging Face.


---
ğŸš€ Features
---
âš¡ Fast local inference using optimized GGUF models  
ğŸ§  Supports quantized LLMs for efficient on-device AI  
ğŸ’» Fully offline â€” no internet or API dependency  
ğŸª¶ Runs on low-RAM systems (consumer-grade hardware)  
ğŸ§© Modular design for easy model swapping and extension  
ğŸ”’ Privacy-friendly (all inference runs locally)  
âš™ï¸ Cross-platform execution (Windows/Linux)  
ğŸ“¦ Lightweight deployment without cloud setup  


## ğŸ“¦ Model Weights

Due to GitHub file size limits, the model is hosted on Hugging Face.

ğŸ”— **Download Model:**
[https://huggingface.co/FREAKKAERF/neuro-nano](https://huggingface.co/FREAKKAERF/neuro-nano)

---

## ğŸ“ Project Structure

```
NEURO-NANO/
â”‚
â”œâ”€â”€ tools/                 # LLaMA / GGML runtime binaries
â”œâ”€â”€ scripts/               # Run & inference scripts
â”œâ”€â”€ SYSTEM_PROMPT.txt      # System prompt config
â”œâ”€â”€ project_documentation.pdf
â”œâ”€â”€ manual.pdf
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/shashwat1237/NEURO-NANO.git
cd NEURO-NANO
```

---

### 2ï¸âƒ£ Download the model

Download `nano.gguf` from:

ğŸ‘‰ [https://huggingface.co/FREAKKAERF/neuro-nano](https://huggingface.co/FREAKKAERF/neuro-nano)

Place it inside:

```
NEURO-NANO/
```

---

### 3ï¸âƒ£ Run the model

#### Windows

```bash
scripts\run_chat.bat
```

#### Linux / Mac

```bash
bash scripts/run_chat.sh
```

---

## ğŸ§  Example (Python Auto-Download)

```python
from huggingface_hub import hf_hub_download

model_path = hf_hub_download(
    repo_id="FREAKKAERF/neuro-nano",
    filename="nano.gguf"
)
```

---

## ğŸ›  Requirements

* Windows / Linux
* Python 3.10+
* Git
* 8GB+ RAM recommended

---

## ğŸ“Œ Notes

* Model files are **not stored in this repo**
* Uses **Git LFS on Hugging Face**
* Designed for **local inference**

---

## ğŸ“œ License

MIT License

---

## ğŸ‘¨â€ğŸ’» Author

**Shashwat**
GitHub: [https://github.com/shashwat1237](https://github.com/shashwat1237)
Model: [https://huggingface.co/FREAKKAERF/neuro-nano](https://huggingface.co/FREAKKAERF/neuro-nano)
 
